#!/usr/bin/env python3
"""
æ•°æ®é›†æ ¼å¼è½¬æ¢å·¥å…·

å°† weibo_senti_100k å’Œ ChnSentiCorp æ•°æ®é›†è½¬æ¢ä¸ºè®­ç»ƒè„šæœ¬éœ€è¦çš„æ ¼å¼ï¼š
- åˆ—åï¼štext, label
- label å€¼ï¼šç§¯æï¼ˆåŸ 1ï¼‰æˆ– æ¶ˆæï¼ˆåŸ 0ï¼‰
"""

import pandas as pd
import argparse
import os
import sys

def convert_dataset(input_file, output_file, text_column='review', label_column='label'):
    """è½¬æ¢æ•°æ®é›†æ ¼å¼"""
    print(f"ğŸ“– è¯»å–æ•°æ®é›†: {input_file}")
    
    try:
        # è¯»å– CSV æ–‡ä»¶
        df = pd.read_csv(input_file, encoding='utf-8')
    except UnicodeDecodeError:
        print("âš ï¸  UTF-8 ç¼–ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç ...")
        try:
            df = pd.read_csv(input_file, encoding='gbk')
        except:
            df = pd.read_csv(input_file, encoding='gb18030')
    
    print(f"   åŸå§‹æ•°æ®é‡: {len(df)} æ¡")
    print(f"   åˆ—å: {df.columns.tolist()}")
    
    # æ£€æŸ¥å¿…éœ€çš„åˆ—
    if text_column not in df.columns:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡æœ¬åˆ— '{text_column}'")
        print(f"   å¯ç”¨åˆ—: {df.columns.tolist()}")
        return False
    
    if label_column not in df.columns:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ ‡ç­¾åˆ— '{label_column}'")
        print(f"   å¯ç”¨åˆ—: {df.columns.tolist()}")
        return False
    
    # åˆ›å»ºæ–°çš„ DataFrame
    result_df = pd.DataFrame()
    result_df['text'] = df[text_column]
    result_df['label'] = df[label_column]
    
    # è½¬æ¢æ ‡ç­¾ï¼š1 -> ç§¯æ, 0 -> æ¶ˆæ
    print("ğŸ”„ è½¬æ¢æ ‡ç­¾æ ¼å¼...")
    label_mapping = {
        1: 'ç§¯æ',
        0: 'æ¶ˆæ',
        '1': 'ç§¯æ',
        '0': 'æ¶ˆæ',
        1.0: 'ç§¯æ',
        0.0: 'æ¶ˆæ'
    }
    
    result_df['label'] = result_df['label'].map(label_mapping)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœªæ˜ å°„çš„æ ‡ç­¾
    unmapped = result_df[result_df['label'].isna()]
    if len(unmapped) > 0:
        print(f"âš ï¸  è­¦å‘Š: å‘ç° {len(unmapped)} æ¡æœªæ˜ å°„çš„æ ‡ç­¾")
        print(f"   æœªæ˜ å°„çš„å€¼: {unmapped['label'].unique().tolist()}")
        # ç§»é™¤æœªæ˜ å°„çš„è¡Œ
        result_df = result_df[result_df['label'].notna()]
    
    # ç§»é™¤ç©ºæ–‡æœ¬
    result_df = result_df[result_df['text'].notna()]
    result_df = result_df[result_df['text'].astype(str).str.strip().str.len() > 0]
    
    print(f"   è½¬æ¢åæ•°æ®é‡: {len(result_df)} æ¡")
    
    # æ˜¾ç¤ºæ ‡ç­¾åˆ†å¸ƒ
    print("\nğŸ“Š æ ‡ç­¾åˆ†å¸ƒ:")
    label_counts = result_df['label'].value_counts()
    for label, count in label_counts.items():
        print(f"   {label}: {count} æ¡ ({count/len(result_df)*100:.1f}%)")
    
    # ä¿å­˜è½¬æ¢åçš„æ•°æ®é›†
    print(f"\nğŸ’¾ ä¿å­˜è½¬æ¢åçš„æ•°æ®é›†: {output_file}")
    result_df.to_csv(output_file, index=False, encoding='utf-8')
    
    print(f"   âœ… è½¬æ¢å®Œæˆï¼")
    return True

def merge_datasets(files, output_file):
    """åˆå¹¶å¤šä¸ªæ•°æ®é›†"""
    print("=" * 70)
    print("åˆå¹¶æ•°æ®é›†")
    print("=" * 70)
    print()
    
    all_dataframes = []
    
    for file in files:
        print(f"ğŸ“– è¯»å–: {file}")
        try:
            df = pd.read_csv(file, encoding='utf-8')
        except UnicodeDecodeError:
            df = pd.read_csv(file, encoding='gbk')
        
        # ç¡®ä¿åˆ—åæ­£ç¡®
        if 'text' not in df.columns or 'label' not in df.columns:
            print(f"   âš ï¸  è·³è¿‡: æ ¼å¼ä¸æ­£ç¡®ï¼ˆéœ€è¦ text å’Œ label åˆ—ï¼‰")
            continue
        
        print(f"   âœ… {len(df)} æ¡æ•°æ®")
        all_dataframes.append(df)
    
    if not all_dataframes:
        print("âŒ é”™è¯¯: æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®é›†å¯ä»¥åˆå¹¶")
        return False
    
    # åˆå¹¶æ•°æ®
    print(f"\nğŸ”€ åˆå¹¶æ•°æ®é›†...")
    merged_df = pd.concat(all_dataframes, ignore_index=True)
    
    # å»é‡ï¼ˆåŸºäºæ–‡æœ¬å†…å®¹ï¼‰
    print(f"   åˆå¹¶å‰: {len(merged_df)} æ¡")
    merged_df = merged_df.drop_duplicates(subset=['text'], keep='first')
    print(f"   å»é‡å: {len(merged_df)} æ¡")
    
    # æ‰“ä¹±æ•°æ®
    merged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š åˆå¹¶åç»Ÿè®¡:")
    print(f"   æ€»æ•°æ®é‡: {len(merged_df)} æ¡")
    label_counts = merged_df['label'].value_counts()
    for label, count in label_counts.items():
        print(f"   {label}: {count} æ¡ ({count/len(merged_df)*100:.1f}%)")
    
    # ä¿å­˜åˆå¹¶åçš„æ•°æ®é›†
    print(f"\nğŸ’¾ ä¿å­˜åˆå¹¶åçš„æ•°æ®é›†: {output_file}")
    merged_df.to_csv(output_file, index=False, encoding='utf-8')
    
    print(f"   âœ… åˆå¹¶å®Œæˆï¼")
    return True

def main():
    parser = argparse.ArgumentParser(
        description='è½¬æ¢å’Œåˆå¹¶ä¸­æ–‡æƒ…æ„Ÿåˆ†ææ•°æ®é›†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è½¬æ¢å•ä¸ªæ•°æ®é›†
  python3 convert_datasets.py \\
      --input datasets/weibo_senti_100k.csv \\
      --output datasets/weibo_senti_100k_converted.csv \\
      --text-column review \\
      --label-column label

  # è½¬æ¢å¹¶åˆå¹¶å¤šä¸ªæ•°æ®é›†
  python3 convert_datasets.py \\
      --merge \\
      --inputs datasets/weibo_senti_100k_converted.csv datasets/ChnSentiCorp_converted.csv \\
      --output datasets/dataset_merged.csv
        """
    )
    
    parser.add_argument(
        '--input',
        type=str,
        help='è¾“å…¥æ•°æ®é›†æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--output',
        type=str,
        help='è¾“å‡ºæ•°æ®é›†æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--text-column',
        type=str,
        default='review',
        help='æ–‡æœ¬åˆ—åï¼ˆé»˜è®¤: reviewï¼‰'
    )
    parser.add_argument(
        '--label-column',
        type=str,
        default='label',
        help='æ ‡ç­¾åˆ—åï¼ˆé»˜è®¤: labelï¼‰'
    )
    parser.add_argument(
        '--merge',
        action='store_true',
        help='åˆå¹¶å¤šä¸ªæ•°æ®é›†'
    )
    parser.add_argument(
        '--inputs',
        nargs='+',
        help='è¦åˆå¹¶çš„æ•°æ®é›†æ–‡ä»¶åˆ—è¡¨ï¼ˆä½¿ç”¨ --merge æ—¶ï¼‰'
    )
    
    args = parser.parse_args()
    
    if args.merge:
        # åˆå¹¶æ¨¡å¼
        if not args.inputs or not args.output:
            print("âŒ é”™è¯¯: åˆå¹¶æ¨¡å¼éœ€è¦ --inputs å’Œ --output å‚æ•°")
            sys.exit(1)
        
        success = merge_datasets(args.inputs, args.output)
    else:
        # è½¬æ¢æ¨¡å¼
        if not args.input or not args.output:
            print("âŒ é”™è¯¯: è½¬æ¢æ¨¡å¼éœ€è¦ --input å’Œ --output å‚æ•°")
            sys.exit(1)
        
        success = convert_dataset(
            args.input,
            args.output,
            text_column=args.text_column,
            label_column=args.label_column
        )
    
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()

